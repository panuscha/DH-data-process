{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vykreslení místa vydání exilových časopisů do mapy\n",
    "\n",
    "V tomto notebooku budeme pracovat s vybranými daty Bibliografie českého literárního exilu. Ta obsahuje záznamy o knihách a statích s literární tématikou, vydaných a publikovaných v českých exilových nakladatelstvích a časopisech. Nás budou zajímat pouze záznamy o statích, u kterých jsou uvedeny časopis a místo vydání. Ty najdeme v poli `773 $t`.  <br>\n",
    "Ukážeme si, jak z dat získat a upravit místo vydání záznamu, zjistit jeho souřadnice a následně místo zobrazit na mapě pomocí knihovny `geopandas` a `matplotlib`.   <br>\n",
    "\n",
    "Tento notebook je určený jak pro začátečníky, tak pro ty, kteří se chtějí seznámit se zpracováním bibliografických dat v Pythonu.\n",
    "\n",
    "## Požadavky\n",
    "\n",
    "K práci s notebookem je potřeba mít vytvořený CSV soubor z notebooku Explore Data.<br>\n",
    "\n",
    "## Předpoklady\n",
    "\n",
    "Tento notebook nepředpokládá hluboké znalosti Pythonu, ale základní znalost programování bude užitečná.<br> \n",
    "\n",
    "## Struktura notebooku\n",
    "\n",
    "Notebook je rozdělen do několika částí:\n",
    "\n",
    "0. **Příprava**: Přidáme potřebné knihovny, které budeme používat ke zpracování marcového souboru. \n",
    "\n",
    "1. **Načtení z CSV**: Ukážeme si, jak načíst naše data uložená v CSV.\n",
    "\n",
    "2. **Extrahování místa vydání**: Z dat najdeme místo zjistíme místo vydání.\n",
    "\n",
    "3. **Čistění dat**: Místa vydání, která obsahují překlepy atp. opravíme. \n",
    "\n",
    "4. **Zjištění souřadnic míst**: Naučíme se, jak pomocí API zjistit souřadnice místa vydání. Výsledek si uložíme do CSV souboru.\n",
    "\n",
    "5. **Načtení souřadnic**: Souřadnice načteme z CSV souboru.\n",
    "\n",
    "6. **Mapa**: Na závěr naše data zaneseme do mapy, kterou i vykreslíme.\n",
    "\n",
    "## Další zdroje\n",
    "\n",
    "- [LearnPython.org](https://www.learnpython.org/): Tento online kurz nabízí výuku jazyka Python pro začátečníky i pokročilé. Může být užitečným zdrojem pro ty, kteří chtějí rozšířit své znalosti Pythonu.\n",
    "- [W3Schools.com/Python](https://www.w3schools.com/python/): Obsáhlý tutoriál, který provází i některými oblíbenými knihovnamy Pythonu. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the Publication Location of Exile Magazines\n",
    "\n",
    "In this notebook, we will work with selected data from the Czech Literary Exile Bibliography. It contains records of books and articles, published by Czech exile publishers and magazines. We will focus only on records of articles that include the magazine and place of publication, which can be found in the `773 $t` field.\n",
    "\n",
    "This notebook will show you how to extract the place of publication from the data, obtain its coordinates, and then visualize it on a map using the `geopandas` and `matplotlib` libraries.\n",
    "\n",
    "This notebook is suitable for both beginners and those who want to familiarize themselves with data processing in Python.\n",
    "\n",
    "## Requirements\n",
    "\n",
    "To work with this notebook, you need to have a CSV file created from the Explore Data notebook.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "This notebook does not require deep knowledge of Python, but a basic understanding of programming will be helpful.\n",
    "\n",
    "## Notebook Structure\n",
    "\n",
    "The notebook is divided into several sections:\n",
    "\n",
    "0. **Preparation**: We will add the necessary libraries for processing the MARC file.\n",
    "\n",
    "1. **Loading from CSV**: We will show how to load our data stored in a CSV file.\n",
    "\n",
    "2. **Extraction of Publication Place**: From the data, we will find and extract the place of publication.\n",
    "\n",
    "3. **Data Cleaning**: We will correct errors in the places of publication, such as typos, etc.\n",
    "\n",
    "4. **Obtaining Place Coordinates**: We will learn how to obtain the coordinates of the publication place using an API and save the results to a CSV file.\n",
    "\n",
    "5. **Loading Coordinates**: We will load the coordinates from the CSV file.\n",
    "\n",
    "6. **Map**: Finally, we will plot our data on a map.\n",
    "\n",
    "## Additional Resources\n",
    "\n",
    "- [LearnPython.org](https://www.learnpython.org/): This online course offers Python tutorials for both beginners and advanced learners. It can be a useful resource for those looking to expand their Python knowledge.\n",
    "\n",
    "- [W3Schools.com/Python](https://www.w3schools.com/python/): An extensive tutorial that covers Python along with some popular Python libraries.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Preparation\n",
    "First, we need to install the libraries we will be working with. Libraries are packages of functions that are not part of the Python language's core. <br>\n",
    "To install libraries, use the command `%pip install <library_name>`. Then, we add them to our notebook using the command `import <library_name> (as alias)`. To access functions from the library, use `library_name.function_name` <br>\n",
    "If we only want to use a single function from a library, we add it using `from <library_name> import <function_name>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install libraries\n",
    "%pip install geopandas\n",
    "%pip install matplotlib\n",
    "%pip install numpy \n",
    "%pip install pandas\n",
    "%pip install requests\n",
    "%pip install shapely\n",
    "\n",
    "# Add libraries\n",
    "from collections import Counter\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "from shapely.geometry import Point\n",
    "from statistics import median, mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load from CSV\n",
    "\n",
    "First, we use the `pandas` library to load our saved CSV data into a DataFrame data structure (similar to an Excel table). Rows in the DataFrame represent individual records, columns represent different types of data (e.g., author names).\n",
    "Some fields and subfields may repeat. In the CSV they are concatenated with semicolons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select base\n",
    "base = 'cle'\n",
    "\n",
    "# Path to our data\n",
    "csv_data = 'data/csv/out_{base}.csv'.format(base = base)\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(csv_data, delimiter=',')\n",
    "\n",
    "print(\"Data loaded to DataFrame df.\")\n",
    "\n",
    "# Iterate through column in the DataFrame\n",
    "for column in df.columns:\n",
    "    # There is only one publication date, so we don't need to split this column\n",
    "    if column != 'year': \n",
    "\n",
    "        # Split joined values into a list \n",
    "        df[column] = df[column].apply(lambda x: x.split(';') if isinstance(x, str)  else [])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podíváme, jak naše data v tabulce vypadají. Nejprve si vypíšeme, kolik záznamů obsahuje informaci o časopisu. To jsou záznamy o statích, které nás budou zajímat. Zbylé budeme považvat za záznamy o knihách. Pak si vypíšeme prvních 5 a posledních 5 položek v DataFramu. <br>\n",
    "\n",
    "Nejprve si pomocí lambda funkce najdeme řádky, které obsahují informaci o časopisu. K nim přiřadíme 1 a všechny sečteme. Tím získáme celkový počet záznamů o statích. <br>\n",
    "Od celkového počtu záznamů pak počet záznamů o statích odečteme, čímž získáme počet záznamů o knihách. Do našeho DataFramu `df` si nakonec uložíme jen záznamy o statích. \n",
    "\n",
    "###### Pokud bychom chtěli přesná data, v marcovém záznamu je kolonka LDR (leader), která nese informaci o typu záznamu. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll take a look at our data. First, we'll determine how many records contain information about magazines. These are the records about articles that interest us. The remaining records will be considered as book records. Then, we'll display the first 5 and the last 5 items in the DataFrame.\n",
    "\n",
    "First, using a lambda function, we'll find rows that contain information about magazines. We'll assign 1 to them and sum them all up. This will give us the total number of article records.<br>\n",
    "To obtain the number of book records, we'll subtract the total number of article records from the overall record count. Finally, we'll keep only the records about articles in our DataFrame df.\n",
    "\n",
    "###### Note: If you require more precise data, the MARC record contains a field called LDR (leader) that carries information about the record type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count nonempty rows \n",
    "magazines_counts = df['magazine'].apply(lambda x: 1 if len(x) > 0 else 0)\n",
    "\n",
    "sum_magazines_counts = magazines_counts.sum()\n",
    "\n",
    "print(\"Number of article records: \", sum_magazines_counts)\n",
    "\n",
    "sum_books_counts = len(df) - sum_magazines_counts\n",
    "\n",
    "print(\"Number of books records: \", sum_books_counts)\n",
    "\n",
    "# Filter book record \n",
    "df = df[df['magazine'].apply(lambda x: len(x) > 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak vidíme, statě tvoří většinu databáze.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that articles are in the majority. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print first 5 records in the DataFrame 'df'\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print last 5 records in the DataFrame 'df'\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vypsali jsme si i začátek a konec našeho DataFramu. Můžeme si všimnout, že u jména časopisu je v kulatých závorkách napsané místo vydání, a že není napsáno u všech. \n",
    "\n",
    "### 2. Extrahování místa vydání\n",
    "\n",
    "Vyextrahujeme si tedy místo vydání a zjisíme, kolik záznamů nemá místo vydání. K tomu využijeme regulární výraz, který nám najde řetězec (slovo) v kulatých závorkách. Záznamy, které mají časopis, ale ne místo vydání, budou vracet hodnotu None. Hodnoty None pak spočteme. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have displayed the beginning and end of our DataFrame. We can observe that the place of publication is written in parentheses next to the journal name and that it is not present in all records.\n",
    "\n",
    "### 2. Extracting the Place of Publication\n",
    "\n",
    "Now, we extract the place of publication and determine how many records lack this information. To achieve this, we use a regular expression that finds the substring (word) within parentheses. Records that have a magazine but lack a place of publication return a None value. We then count the None values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex pattern, that finds string inside columns\n",
    "pattern_cities = r\"\\((.*?)\\)\"\n",
    "\n",
    "# Save cities (substring inside brackets) to list \n",
    "cities = df['magazine'].apply(lambda x: [re.search(pattern_cities, y).group(1) if re.search(pattern_cities, y) else None for y in x]).tolist().copy()\n",
    "\n",
    "# Count all values that have None values -> magazines without \n",
    "sum_None =  sum(list(map(lambda x : 1 if (len(x) == 1 and x[0] is None) else 0, cities )))\n",
    "\n",
    "print(\"Počet časopisů bez místa vydání: \", sum_None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak vidíme, není to příliš mnoho záznamů, a proto se jimi nemusíme trápit. <br>\n",
    "\n",
    "Teď už nám jen zbývá zjistit místa vydání a jejich četnost výskytů. <br> \n",
    "\n",
    "Abychom nemuseli psát stejný kód několikrát, napíšeme ho jednou do funkce, kterou pak jednoduše zavoláme. V tomto případě si napíšeme funkci, která nám z několika listů (seznamů) vnořených do sebe vytvoří jeden. To se nám bude hodit, až budeme chtít spočítat četnost výskytů míst vydání. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, there aren't too many records to handle, so we don't need to worry about them.\n",
    "\n",
    "Now, we determine the places of publication and their frequencies.\n",
    "\n",
    "To avoid writing the same code multiple times, we write it once as a function that we can later easily call. In this case, we write a function that creates one list from several nested lists. This will be useful when we want to calculate frequencies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that flattens nested lists \n",
    "def flatten_list(strings):\n",
    "    flattened_list = []\n",
    "    if strings is not None: # Check if element is not None\n",
    "        for item in strings:\n",
    "            if isinstance(item, str):  # If element is a string, add it to the list\n",
    "                flattened_list.append(item)\n",
    "            elif isinstance(item, list):  # Recursion\n",
    "                flattened_list.extend(flatten_list(item))\n",
    "        return flattened_list\n",
    "\n",
    "print(\"Function saved\")             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zjistíme, jaká místa vydání se v naší databázi objevují."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find which places of publication are in our database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a flatten list that deletes also None values \n",
    "cities = flatten_list(cities)\n",
    "\n",
    "print(\"Unique places of publication:\", np.unique(cities))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Čistění dat\n",
    "\n",
    "Z uniktních hodnot vidíme, že některá města jsou uložena jak pod svým původím jménem, tak pod svou českou alternativou (London - Londýn, Köln - Kolín nad Rýnem). U některých jsou překlepy (Wintertuhr-Obstladen -> Winterthur-Obstalden), které musíme opravit. U některých je zase měst více (Wintertuhr-Obstladen , Ženeva-Middlesex-Mnichov). V tomto případě si všechna města uložíme v listu.<br>\n",
    "Použijeme k tomu funkci `lambda` a `map()`, která funguje stejně jako funkce `apply()` v knihovně `pandas`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data Cleaning\n",
    "\n",
    "From the unique values, we can see that some cities are stored under their original name as well as under their Czech alternative (London - Londýn, Köln - Kolín nad Rýnem). Some have typos (Wintertuhr-Obstladen -> Winterthur-Obstalden) that need to be corrected. Others contain multiple cities (Wintertuhr-Obstladen, Ženeva-Middlesex-Mnichov). In this case, we store all cities in a list.\n",
    "\n",
    "We use the `lambda` function and `map()`, which works similarly to the `apply()` function in the `pandas` library.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete Index on Censorship from an element 'London, Index on Censorship', combine 'London' and 'Londýn'\n",
    "cities = list(map(lambda x: 'Londýn' if 'London' in x else x, cities))\n",
    "\n",
    "# Correct 'Obstladen' -> 'Obstalden' and Winterthur\n",
    "cities = list(map(lambda x: ['Winterthur', 'Obstalden'] if 'Obstladen' in x else x, cities))\n",
    "\n",
    "# Create two elements from 'New York-Paříž'\n",
    "cities = list(map(lambda x: ['New York','Paříž'] if 'New York-Paříž' in x else x, cities))\n",
    "\n",
    "# Create three elements from 'Ženeva-Middlesex-Mnichov'\n",
    "cities = list(map(lambda x: ['Ženeva','Middlesex', 'Mnichov'] if 'Ženeva-Middlesex-Mnichov' in x else x, cities))\n",
    "\n",
    "# Overwrite 'Köln-Ehrenfeld' to 'Kolín nad Rýnem'\n",
    "cities = list(map(lambda x: 'Kolín nad Rýnem' if 'Köln-Ehrenfeld' in x else x, cities))\n",
    "\n",
    "# Flatten list \n",
    "cities = flatten_list(cities)\n",
    "\n",
    "print(\"Unique places of publication after correction:\", np.unique(cities))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pomocí funkce `Counter()` spočteme četnost míst vydání. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We count the number of records using `Counter()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of occurences \n",
    "cities_number_of_records = Counter(cities)\n",
    "\n",
    "print(cities_number_of_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Převedeme z dictionary do DataFramu `cities_df`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We convert our dictionary to DataFrame `cities_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame\n",
    "cities_df = pd.DataFrame.from_dict(cities_number_of_records, orient='index').reset_index()\n",
    "\n",
    "# Add column titles\n",
    "cities_df.columns = ['city', 'number of records']\n",
    "\n",
    "# Print \n",
    "cities_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Zjištění souřadnic míst\n",
    "\n",
    "Tento kód je ukázka toho, jak pomocí API získat souřadnice měst. Je k němu potřeba osobní API klíč, který lze zíkat z této stránky - https://opencagedata.com/api. Ten se jen přidá do proměnné `api_key`. Kód pak vyšle request přes url stránku s naším API klíčem a jménem města. Pokud request proběhne v pořádku, funkce vrátí zeměpisnou šířku (latitude) a výšku (longitude)<br>\n",
    "\n",
    "<i> Tato buňka se nespustí. Pro spuštění je potřeba vymazat první řádek `%%script echo skip` </i>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo skip\n",
    "\n",
    "# Function that find coordinates of a city by it's name\n",
    "def get_city_coordinates(city):\n",
    "    api_key = \"MY KEY\"\n",
    "    url = f\"https://api.opencagedata.com/geocode/v1/json?q={city}&key={api_key}\"\n",
    "\n",
    "    # Call request function\n",
    "    response = requests.get(url)\n",
    "\n",
    "    data = response.json()\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        # If the city is found, save coordinates\n",
    "        if data[\"total_results\"] > 0:\n",
    "            lat = data[\"results\"][0][\"geometry\"][\"lat\"]\n",
    "            lon = data[\"results\"][0][\"geometry\"][\"lng\"]\n",
    "            return lat, lon\n",
    "        else:\n",
    "            print(\"No results found for the city.\")\n",
    "    else:\n",
    "        print(\"Error occurred while fetching data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pomocí funkce get_city_coordinates, kterou jsme si napsali v předchozí buňce, zjistíme souřadnice měst, která si zapíšeme do DataFramu. Na konci se DataFrame uloží do CSV souboru. \n",
    "\n",
    "<i> Tato buňka se nespustí. Pro spuštění je potřeba vymazat první řádek `%%script echo skip` </i>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Using the `get_city_coordinates` function  we obtain the coordinates of cities and save them in a DataFrame. At the end, the DataFrame will be saved to a CSV file.\n",
    "\n",
    "<i> This cell will not run. To execute it, you need to remove the first line %%script echo skip. </i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo skip\n",
    "\n",
    "cities_df['latitude'] = None\n",
    "cities_df['longitude'] = None\n",
    "df.reindex(columns=['city', 'number of records', 'lat', 'lon'], fill_value=0)\n",
    "\n",
    "# Unique cities\n",
    "unique_cities = np.unique(cities)\n",
    "coordinates = {}\n",
    "\n",
    "# Iterate unique cities\n",
    "for city in unique_cities:\n",
    "    # Try except to catch mistakes\n",
    "    try:\n",
    "        (latitude, longitude) = get_city_coordinates(city)\n",
    "        print(f\"Coordinates of {city}: Latitude={latitude}, Longitude={longitude}\")\n",
    "        coordinates[city] = (latitude, longitude)\n",
    "        cities_df.loc[cities_df['city'] == city, 'latitude'] = latitude\n",
    "        cities_df.loc[cities_df['city'] == city, 'longitude'] = longitude\n",
    "    except:\n",
    "        print(f\"City {city} not found.\")\n",
    "          \n",
    "# Create DataFrame from dictionary\n",
    "df_coordinates = pd.DataFrame.from_dict(coordinates)\n",
    "\n",
    "# Transpose table\n",
    "df_coordinates = df_coordinates.T\n",
    "\n",
    "df_coordinates.to_csv('data/coordinates/coordinates.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Načtení souřadnic\n",
    "\n",
    "Výsledek přechozícho kódu jsme si uložili do souboru coordinates.csv, ze kterého si data teď načteme.   \n",
    "CSV soubor obsahuje seznam míst, u kterých se připsaná zeměpisná šířka (latitude) a výška (longitude)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Loading Coordinates\n",
    "\n",
    "We saved the result to 'coordinates.csv'. We now load our data from the file. \n",
    "CSV file contains list of cities with their latitude and longitude. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load coordinates from a file \n",
    "df_coordinates = pd.read_csv('data/coordinates/coordinates.csv')\n",
    "\n",
    "# Add column titles\n",
    "df_coordinates.columns = ['city','latitude', 'longitude']\n",
    "\n",
    "# Merge tables together\n",
    "points_df = pd.merge(cities_df, df_coordinates)\n",
    "\n",
    "points_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Mapa\n",
    "\n",
    "V poslední části si data vykreslíme do mapy, kterou máme připravenou ve složce data/geojson. Nejprve si určíme, jakou část světa budeme chtít vykreslit. Pak postupně města-body zaneseme do mapy. Velikost bodu se bude odvíjet od počtu vydaných článků. Přidáme i legendu, případně i popisky k jednotlivým městům.  \n",
    "\n",
    "#### 6.1 Ohraničení mapy\n",
    "\n",
    "Jelikož se všechna města nachází buď v Evropě nebo v severní Americe, můžeme mapu světa, kterou budeme vykrelovat, ohraničit. Ohraničení definujeme pomocí minimální a maximální zeměpisné výšky a šířky. Následně pak vyřadíme všechna města, která jsou mimo ohraničení. <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Map\n",
    "In the final section, we visualize the data on a map, which is prepared in the 'data/geojson' folder. First, we determine which part of the world we want to display. Then, we will gradually plot cities as points on the map. The size of the points will depend on the number of published articles. We will also add a legend and, if necessary, labels for individual cities.\n",
    "\n",
    "##### 6.1 Bounding box\n",
    "Since all the cities are located either in Europe or North America, we can define the bounding box of the world map we plot. We define the box using minimum and maximum latitude and longitude. Then, we remove all cities that are outside of this boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bounding box of our map  \n",
    "bbox = [-130, 15, 50, 80]  # [minx, miny, maxx, maxy] - minimal longitude, minimal latitude, maximal longitude, maximal latitude \n",
    "\n",
    "# List of cities we want to omit  \n",
    "remove = []\n",
    "\n",
    "# Iterate through DataFrame\n",
    "for _, row in points_df.iterrows():\n",
    "    lat = row['latitude']\n",
    "    lon = row['longitude']\n",
    "    minx = bbox[0]\n",
    "    miny = bbox[1]\n",
    "    maxx = bbox[2]\n",
    "    maxy = bbox[3]\n",
    "    \n",
    "    # All cities that are outside of the bounding box add to remove list\n",
    "    if lon < minx or lat < miny or lon > maxx or lat > maxy:\n",
    "        remove.append(row['city'])\n",
    "\n",
    "# Remove cities that are on the remove list \n",
    "points_df = points_df[~points_df['city'].isin(remove)]\n",
    "\n",
    "points_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-block alert-info'>\n",
    "    <b>Try It!</b>  You can experiment with different geographical boundaries. <br>\n",
    "For example, [-130, 15, 50, 80] is the bounding box of North America and Europe. [-5, 35, 30, 55] is an approximate boundary of Europe. [6, 45, 11, 48] roughly defines the border of Switzerland. <br> \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2 Map Visualization\n",
    "\n",
    "We use the `geopandas` and `matplotlib` libraries for visualization.<br> \n",
    "First, we create `Point` objects from longitude and latitude using the `shapely` library and convert them into a `GeoDataFrame`, which can be easily plotted on a map.<br>\n",
    "We load the map and plot it. Our map will be displayed according to the bounding box defined in the previous cell.<br>\n",
    "We then add points to the map - our places of publication - based on their longitude and latitude. The size of the points depend on the number of articles published in that location. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create shapely points from longitude and latitude of each city\n",
    "geometry = [Point(lon, lat) for lon, lat in zip(points_df['longitude'], points_df['latitude'])]\n",
    "\n",
    "# Convert DataFrame to GeoDataFrame\n",
    "points_gdf = gpd.GeoDataFrame(points_df, geometry=geometry, crs=\"EPSG:4326\") \n",
    "\n",
    "# Load map \n",
    "base_map_data = gpd.read_file(\"data/geojson/world_1960.geojson\")\n",
    "\n",
    "# Set figure size \n",
    "figsize = (15,12)\n",
    "\n",
    "plt.figure(figsize=figsize)\n",
    "\n",
    "# Bound the map \n",
    "ax = base_map_data.clip(bbox).plot(figsize=figsize)\n",
    "\n",
    "# Parameter for point size \n",
    "div = 10\n",
    "\n",
    "# Parameter for annotating the point\n",
    "ann = False\n",
    "\n",
    "# Plot map and cities-points\n",
    "points_gdf.plot(figsize=figsize,\n",
    "                ax=ax, \n",
    "                color = \"red\",\n",
    "                marker = 'o',\n",
    "                markersize=points_gdf['number of records'].apply(lambda x: x/div),  # Set point size  \n",
    "                )\n",
    "\n",
    "# If parameter is set to True, annotate points \n",
    "if ann:\n",
    "     # Add name of the cities as labels\n",
    "     for x, y, label in zip(points_df.longitude, points_df.latitude, points_df.city):\n",
    "          ax.annotate(label, xy=(x, y), xytext=(3, 3), textcoords=\"offset points\", fontsize = 8)\n",
    "\n",
    "# Set sizes of legend points\n",
    "point_sizes = [min(points_gdf['number of records'].apply(lambda x: int(round(x, -1)))), mean(points_gdf['number of records'].apply(lambda x: int(round(x, -1)))), max(points_gdf['number of records'].apply(lambda x: int(round(x, -1))))]\n",
    "\n",
    "# Create legend points\n",
    "legend_handles = [Line2D([], [], marker = 'o', lw=0, color='red', markersize=np.sqrt(size/div), label=str(int(round(size, -1)))) for size in point_sizes]\n",
    "\n",
    "# Add legend\n",
    "ax.legend(handles=legend_handles, title='Number of Records', loc='upper right')\n",
    "\n",
    "plt.title(\"Exile magazines \")\n",
    "plt.grid(False)\n",
    "ax.set_axis_off()  \n",
    "plt.savefig(\"plots/exil_cropped_map.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-block alert-info'>\n",
    "    <b>Try It!</b> The code includes two parameters - div and ann.<br> \n",
    "    Using the div parameter, you can change the point size. A higher value will result in smaller points. Higher values are more suitable for maps that cover larger areas to prevent points from overlapping.    \n",
    "    The ann parameter adds city labels. When set to True, it adds the city name next to its point.\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
