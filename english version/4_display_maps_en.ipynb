{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the Publication Location of Exile Magazines\n",
    "\n",
    "In this notebook, we will work with selected data from the Czech Literary Exile Bibliography. It contains records of books and articles, published by Czech exile publishers and magazines. We will focus only on records of articles that include the magazine and place of publication, which can be found in the `773 $t` field.\n",
    "\n",
    "This notebook will show you how to extract the place of publication from the data, obtain its coordinates, and then visualize it on a map using the `geopandas` and `matplotlib` libraries.\n",
    "\n",
    "This notebook is suitable for both beginners and those who want to familiarize themselves with data processing in Python.\n",
    "\n",
    "## Requirements\n",
    "\n",
    "To work with this notebook, you need to have a CSV file created from the Explore Data notebook.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "This notebook does not require deep knowledge of Python, but a basic understanding of programming will be helpful.\n",
    "\n",
    "## Notebook Structure\n",
    "\n",
    "The notebook is divided into several sections:\n",
    "\n",
    "0. **Preparation**: We will add the necessary libraries for processing the MARC file.\n",
    "\n",
    "1. **Loading from CSV**: We will show how to load our data stored in a CSV file.\n",
    "\n",
    "2. **Extraction of Publication Place**: From the data, we will find and extract the place of publication.\n",
    "\n",
    "3. **Data Cleaning**: We will correct errors in the places of publication, such as typos, etc.\n",
    "\n",
    "4. **Obtaining Place Coordinates**: We will learn how to obtain the coordinates of the publication place using an API and save the results to a CSV file.\n",
    "\n",
    "5. **Loading Coordinates**: We will load the coordinates from the CSV file.\n",
    "\n",
    "6. **Map**: Finally, we will plot our data on a map.\n",
    "\n",
    "## Additional Resources\n",
    "\n",
    "- [LearnPython.org](https://www.learnpython.org/): This online course offers Python tutorials for both beginners and advanced learners. It can be a useful resource for those looking to expand their Python knowledge.\n",
    "\n",
    "- [W3Schools.com/Python](https://www.w3schools.com/python/): An extensive tutorial that covers Python along with some popular Python libraries.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Preparation\n",
    "First, we need to install the libraries we will be working with. Libraries are packages of functions that are not part of the Python language's core. <br>\n",
    "To install libraries, use the command `%pip install <library_name>`. Then, we add them to our notebook using the command `import <library_name> (as alias)`. To access functions from the library, use `library_name.function_name` <br>\n",
    "If we only want to use a single function from a library, we add it using `from <library_name> import <function_name>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install libraries\n",
    "%pip install geopandas\n",
    "%pip install matplotlib\n",
    "%pip install numpy \n",
    "%pip install pandas\n",
    "%pip install requests\n",
    "%pip install shapely\n",
    "\n",
    "# Add libraries\n",
    "from collections import Counter\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "from shapely.geometry import Point\n",
    "from statistics import median, mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load from CSV\n",
    "\n",
    "First, we use the `pandas` library to load our saved CSV data into a DataFrame data structure (similar to an Excel table). Rows in the DataFrame represent individual records, columns represent different types of data (e.g., author names).\n",
    "Some fields and subfields may repeat. In the CSV they are concatenated with semicolons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select base\n",
    "base = 'cle'\n",
    "\n",
    "# Path to our data\n",
    "csv_data = 'data/csv/out_{base}.csv'.format(base = base)\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(csv_data, delimiter=',')\n",
    "\n",
    "print(\"Data loaded to DataFrame df.\")\n",
    "\n",
    "# Iterate through column in the DataFrame\n",
    "for column in df.columns:\n",
    "    # There is only one publication date, so we don't need to split this column\n",
    "    if column != 'year': \n",
    "\n",
    "        # Split joined values into a list \n",
    "        df[column] = df[column].apply(lambda x: x.split(';') if isinstance(x, str)  else [])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll take a look at our data. First, we'll determine how many records contain information about magazines. These are the records about articles that interest us. The remaining records will be considered as book records. Then, we'll display the first 5 and the last 5 items in the DataFrame.\n",
    "\n",
    "First, using a lambda function, we'll find rows that contain information about magazines. We'll assign 1 to them and sum them all up. This will give us the total number of article records.<br>\n",
    "To obtain the number of book records, we'll subtract the total number of article records from the overall record count. Finally, we'll keep only the records about articles in our DataFrame df.\n",
    "\n",
    "###### Note: If you require more precise data, the MARC record contains a field called LDR (leader) that carries information about the record type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count nonempty rows \n",
    "magazines_counts = df['magazine'].apply(lambda x: 1 if len(x) > 0 else 0)\n",
    "\n",
    "sum_magazines_counts = magazines_counts.sum()\n",
    "\n",
    "print(\"Number of article records: \", sum_magazines_counts)\n",
    "\n",
    "sum_books_counts = len(df) - sum_magazines_counts\n",
    "\n",
    "print(\"Number of books records: \", sum_books_counts)\n",
    "\n",
    "# Filter book record \n",
    "df = df[df['magazine'].apply(lambda x: len(x) > 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that articles are in the majority. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print first 5 records in the DataFrame 'df'\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print last 5 records in the DataFrame 'df'\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have displayed the beginning and end of our DataFrame. We can observe that the place of publication is written in parentheses next to the journal name and that it is not present in all records.\n",
    "\n",
    "### 2. Extracting the Place of Publication\n",
    "\n",
    "Now, we extract the place of publication and determine how many records lack this information. To achieve this, we use a regular expression that finds the substring (word) within parentheses. Records that have a magazine but lack a place of publication return a None value. We then count the None values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex pattern, that finds string inside columns\n",
    "pattern_cities = r\"\\((.*?)\\)\"\n",
    "\n",
    "# Save cities (substring inside brackets) to list \n",
    "cities = df['magazine'].apply(lambda x: [re.search(pattern_cities, y).group(1) if re.search(pattern_cities, y) else None for y in x]).tolist().copy()\n",
    "\n",
    "# Count all values that have None values -> magazines without \n",
    "sum_None =  sum(list(map(lambda x : 1 if (len(x) == 1 and x[0] is None) else 0, cities )))\n",
    "\n",
    "print(\"Počet časopisů bez místa vydání: \", sum_None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, there aren't too many records to handle, so we don't need to worry about them.\n",
    "\n",
    "Now, we determine the places of publication and their frequencies.\n",
    "\n",
    "To avoid writing the same code multiple times, we write it once as a function that we can later easily call. In this case, we write a function that creates one list from several nested lists. This will be useful when we want to calculate frequencies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that flattens nested lists \n",
    "def flatten_list(strings):\n",
    "    flattened_list = []\n",
    "    if strings is not None: # Check if element is not None\n",
    "        for item in strings:\n",
    "            if isinstance(item, str):  # If element is a string, add it to the list\n",
    "                flattened_list.append(item)\n",
    "            elif isinstance(item, list):  # Recursion\n",
    "                flattened_list.extend(flatten_list(item))\n",
    "        return flattened_list\n",
    "\n",
    "print(\"Function saved\")             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find which places of publication are in our database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a flatten list that deletes also None values \n",
    "cities = flatten_list(cities)\n",
    "\n",
    "print(\"Unique places of publication:\", np.unique(cities))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data Cleaning\n",
    "\n",
    "From the unique values, we can see that some cities are stored under their original name as well as under their Czech alternative (London - Londýn, Köln - Kolín nad Rýnem). Some have typos (Wintertuhr-Obstladen -> Winterthur-Obstalden) that need to be corrected. Others contain multiple cities (Wintertuhr-Obstladen, Ženeva-Middlesex-Mnichov). In this case, we store all cities in a list.\n",
    "\n",
    "We use the `lambda` function and `map()`, which works similarly to the `apply()` function in the `pandas` library.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete Index on Censorship from an element 'London, Index on Censorship', combine 'London' and 'Londýn'\n",
    "cities = list(map(lambda x: 'Londýn' if 'London' in x else x, cities))\n",
    "\n",
    "# Correct 'Obstladen' -> 'Obstalden' and Winterthur\n",
    "cities = list(map(lambda x: ['Winterthur', 'Obstalden'] if 'Obstladen' in x else x, cities))\n",
    "\n",
    "# Create two elements from 'New York-Paříž'\n",
    "cities = list(map(lambda x: ['New York','Paříž'] if 'New York-Paříž' in x else x, cities))\n",
    "\n",
    "# Create three elements from 'Ženeva-Middlesex-Mnichov'\n",
    "cities = list(map(lambda x: ['Ženeva','Middlesex', 'Mnichov'] if 'Ženeva-Middlesex-Mnichov' in x else x, cities))\n",
    "\n",
    "# Overwrite 'Köln-Ehrenfeld' to 'Kolín nad Rýnem'\n",
    "cities = list(map(lambda x: 'Kolín nad Rýnem' if 'Köln-Ehrenfeld' in x else x, cities))\n",
    "\n",
    "# Flatten list \n",
    "cities = flatten_list(cities)\n",
    "\n",
    "print(\"Unique places of publication after correction:\", np.unique(cities))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We count the number of records using `Counter()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of occurences \n",
    "cities_number_of_records = Counter(cities)\n",
    "\n",
    "print(cities_number_of_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We convert our dictionary to DataFrame `cities_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame\n",
    "cities_df = pd.DataFrame.from_dict(cities_number_of_records, orient='index').reset_index()\n",
    "\n",
    "# Add column titles\n",
    "cities_df.columns = ['city', 'number of records']\n",
    "\n",
    "# Print \n",
    "cities_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Obtaining Location Coordinates\n",
    "\n",
    "This code demonstrates how to obtain the coordinates of cities using an API. It requires a personal API key, which can be obtained from this website - https://opencagedata.com/api. You simply need to add the API key to the `api_key` variable. The code then sends a request to the URL with our API key and the city name. If the request is successful, the function returns the latitude and longitude.\n",
    "\n",
    "<i> This cell will not run. To execute it, you need to remove the first line `%%script echo skip`. </i>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo skip\n",
    "\n",
    "# Function that find coordinates of a city by it's name\n",
    "def get_city_coordinates(city):\n",
    "    api_key = \"MY KEY\"\n",
    "    url = f\"https://api.opencagedata.com/geocode/v1/json?q={city}&key={api_key}\"\n",
    "\n",
    "    # Call request function\n",
    "    response = requests.get(url)\n",
    "\n",
    "    data = response.json()\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        # If the city is found, save coordinates\n",
    "        if data[\"total_results\"] > 0:\n",
    "            lat = data[\"results\"][0][\"geometry\"][\"lat\"]\n",
    "            lon = data[\"results\"][0][\"geometry\"][\"lng\"]\n",
    "            return lat, lon\n",
    "        else:\n",
    "            print(\"No results found for the city.\")\n",
    "    else:\n",
    "        print(\"Error occurred while fetching data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Using the `get_city_coordinates` function  we obtain the coordinates of cities and save them in a DataFrame. At the end, the DataFrame will be saved to a CSV file.\n",
    "\n",
    "<i> This cell will not run. To execute it, you need to remove the first line %%script echo skip. </i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo skip\n",
    "\n",
    "cities_df['latitude'] = None\n",
    "cities_df['longitude'] = None\n",
    "df.reindex(columns=['city', 'number of records', 'lat', 'lon'], fill_value=0)\n",
    "\n",
    "# Unique cities\n",
    "unique_cities = np.unique(cities)\n",
    "coordinates = {}\n",
    "\n",
    "# Iterate unique cities\n",
    "for city in unique_cities:\n",
    "    # Try except to catch mistakes\n",
    "    try:\n",
    "        (latitude, longitude) = get_city_coordinates(city)\n",
    "        print(f\"Coordinates of {city}: Latitude={latitude}, Longitude={longitude}\")\n",
    "        coordinates[city] = (latitude, longitude)\n",
    "        cities_df.loc[cities_df['city'] == city, 'latitude'] = latitude\n",
    "        cities_df.loc[cities_df['city'] == city, 'longitude'] = longitude\n",
    "    except:\n",
    "        print(f\"City {city} not found.\")\n",
    "          \n",
    "# Create DataFrame from dictionary\n",
    "df_coordinates = pd.DataFrame.from_dict(coordinates)\n",
    "\n",
    "# Transpose table\n",
    "df_coordinates = df_coordinates.T\n",
    "\n",
    "df_coordinates.to_csv('data/coordinates/coordinates.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Loading Coordinates\n",
    "\n",
    "We saved the result to 'coordinates.csv'. We now load our data from the file. \n",
    "CSV file contains list of cities with their latitude and longitude. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load coordinates from a file \n",
    "df_coordinates = pd.read_csv('data/coordinates/coordinates.csv')\n",
    "\n",
    "# Add column titles\n",
    "df_coordinates.columns = ['city','latitude', 'longitude']\n",
    "\n",
    "# Merge tables together\n",
    "points_df = pd.merge(cities_df, df_coordinates)\n",
    "\n",
    "points_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Map\n",
    "In the final section, we visualize the data on a map, which is prepared in the 'data/geojson' folder. First, we determine which part of the world we want to display. Then, we will gradually plot cities as points on the map. The size of the points will depend on the number of published articles. We will also add a legend and, if necessary, labels for individual cities.\n",
    "\n",
    "##### 6.1 Bounding box\n",
    "Since all the cities are located either in Europe or North America, we can define the bounding box of the world map we plot. We define the box using minimum and maximum latitude and longitude. Then, we remove all cities that are outside of this boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bounding box of our map  \n",
    "bbox = [-130, 15, 50, 80]  # [minx, miny, maxx, maxy] - minimal longitude, minimal latitude, maximal longitude, maximal latitude \n",
    "\n",
    "# List of cities we want to omit  \n",
    "remove = []\n",
    "\n",
    "# Iterate through DataFrame\n",
    "for _, row in points_df.iterrows():\n",
    "    lat = row['latitude']\n",
    "    lon = row['longitude']\n",
    "    minx = bbox[0]\n",
    "    miny = bbox[1]\n",
    "    maxx = bbox[2]\n",
    "    maxy = bbox[3]\n",
    "    \n",
    "    # All cities that are outside of the bounding box add to remove list\n",
    "    if lon < minx or lat < miny or lon > maxx or lat > maxy:\n",
    "        remove.append(row['city'])\n",
    "\n",
    "# Remove cities that are on the remove list \n",
    "points_df = points_df[~points_df['city'].isin(remove)]\n",
    "\n",
    "points_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-block alert-info'>\n",
    "    <b>Try It!</b>  You can experiment with different geographical boundaries. <br>\n",
    "For example, [-130, 15, 50, 80] is the bounding box of North America and Europe. [-5, 35, 30, 55] is an approximate boundary of Europe. [6, 45, 11, 48] roughly defines the border of Switzerland. <br> \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2 Map Visualization\n",
    "\n",
    "We use the `geopandas` and `matplotlib` libraries for visualization.<br> \n",
    "First, we create `Point` objects from longitude and latitude using the `shapely` library and convert them into a `GeoDataFrame`, which can be easily plotted on a map.<br>\n",
    "We load the map and plot it. Our map will be displayed according to the bounding box defined in the previous cell.<br>\n",
    "We then add points to the map - our places of publication - based on their longitude and latitude. The size of the points depend on the number of articles published in that location. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create shapely points from longitude and latitude of each city\n",
    "geometry = [Point(lon, lat) for lon, lat in zip(points_df['longitude'], points_df['latitude'])]\n",
    "\n",
    "# Convert DataFrame to GeoDataFrame\n",
    "points_gdf = gpd.GeoDataFrame(points_df, geometry=geometry, crs=\"EPSG:4326\") \n",
    "\n",
    "# Load map \n",
    "base_map_data = gpd.read_file(\"data/geojson/world_1960.geojson\")\n",
    "\n",
    "# Set figure size \n",
    "figsize = (15,12)\n",
    "\n",
    "plt.figure(figsize=figsize)\n",
    "\n",
    "# Bound the map \n",
    "ax = base_map_data.clip(bbox).plot(figsize=figsize)\n",
    "\n",
    "# Parameter for point size \n",
    "div = 10\n",
    "\n",
    "# Parameter for annotating the point\n",
    "ann = False\n",
    "\n",
    "# Plot map and cities-points\n",
    "points_gdf.plot(figsize=figsize,\n",
    "                ax=ax, \n",
    "                color = \"red\",\n",
    "                marker = 'o',\n",
    "                markersize=points_gdf['number of records'].apply(lambda x: x/div),  # Set point size  \n",
    "                )\n",
    "\n",
    "# If parameter is set to True, annotate points \n",
    "if ann:\n",
    "     # Add name of the cities as labels\n",
    "     for x, y, label in zip(points_df.longitude, points_df.latitude, points_df.city):\n",
    "          ax.annotate(label, xy=(x, y), xytext=(3, 3), textcoords=\"offset points\", fontsize = 8)\n",
    "\n",
    "# Set sizes of legend points\n",
    "point_sizes = [min(points_gdf['number of records'].apply(lambda x: int(round(x, -1)))), mean(points_gdf['number of records'].apply(lambda x: int(round(x, -1)))), max(points_gdf['number of records'].apply(lambda x: int(round(x, -1))))]\n",
    "\n",
    "# Create legend points\n",
    "legend_handles = [Line2D([], [], marker = 'o', lw=0, color='red', markersize=np.sqrt(size/div), label=str(int(round(size, -1)))) for size in point_sizes]\n",
    "\n",
    "# Add legend\n",
    "ax.legend(handles=legend_handles, title='Number of Records', loc='upper right')\n",
    "\n",
    "plt.title(\"Exile magazines \")\n",
    "plt.grid(False)\n",
    "ax.set_axis_off()  \n",
    "plt.savefig(\"plots/exil_cropped_map.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-block alert-info'>\n",
    "    <b>Try It!</b> The code includes two parameters - div and ann.<br> \n",
    "    Using the div parameter, you can change the point size. A higher value will result in smaller points. Higher values are more suitable for maps that cover larger areas to prevent points from overlapping.    \n",
    "    The ann parameter adds city labels. When set to True, it adds the city name next to its point.\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
